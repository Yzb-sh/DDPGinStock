# DDPG股票交易强化学习系统

## 项目简介

本项目基于深度确定性策略梯度（DDPG）算法实现了一个智能股票交易系统，旨在通过强化学习技术自动化股票交易决策。系统支持普通DDPG和LSTM增强版DDPG两种模型架构，能够学习复杂的市场模式并制定交易策略。

## 主要特色

- **双模型架构**：支持传统DDPG和LSTM增强版DDPG
- **多种奖励函数**：提供5种不同的奖励函数设计，适应不同交易风格
- **完整评估体系**：包含夏普比率、最大回撤、年化收益等专业指标
- **详细结果记录**：自动保存交易记录、性能分析和可视化图表
- **实时交易建议**：支持基于当前持仓和资金状况的交易建议

## 技术架构

### 核心算法
- **DDPG (Deep Deterministic Policy Gradient)**：连续动作空间的Actor-Critic算法
- **LSTM增强**：长短期记忆网络捕捉时序依赖关系
- **经验回放**：支持序列采样的经验回放缓冲区

### 网络结构
- **Actor网络**：状态 → 交易动作（买入/卖出比例）
- **Critic网络**：状态-动作对 → Q值评估
- **目标网络**：软更新机制提高训练稳定性

## 环境要求

### Python依赖
```bash
torch >= 1.9.0
numpy >= 1.20.0
pandas >= 1.3.0
matplotlib >= 3.4.0
```

### 系统要求
- Python 3.8+
- 支持CUDA的GPU（可选，用于加速训练）
- 内存：建议8GB以上

## 安装使用

### 1. 克隆项目
```bash
git clone https://github.com/Yzb-sh/DDPGinStock.git
cd DDPGinStock（LSTM）
```

### 2. 安装依赖
```bash
pip install torch numpy pandas matplotlib
```

### 3. 准备数据
系统会自动下载指定股票的历史数据，或将数据文件放置在 `./data/` 目录下。

## 使用指南

### 基本命令

#### 1. 训练模型
```bash
# 训练普通DDPG模型 (保存到 ./models/reward-3/ddpg/600016/)
python main.py train --code 600016 --reward 3 --seed 1234

# 训练LSTM增强版DDPG模型 (保存到 ./models/reward-3/ddpg_lstm/600016/)
python main.py train --code 600016 --reward 3 --seed 1234 --model_type ddpg_lstm --seq_len 10
```

#### 2. 测试模型
```bash
# 测试普通DDPG模型 (自动从 ./models/reward-3/ddpg/600016/best.pt 加载)
python main.py test --code 600016 --reward 3 --model_type ddpg

# 测试LSTM模型 (自动从 ./models/reward-3/ddpg_lstm/600016/best.pt 加载)
python main.py test --code 600016 --reward 3 --model_type ddpg_lstm --seq_len 10

# 或者手动指定模型路径 (会自动推断模型类型)
python main.py test --code 600016 --model ./models/reward-3/ddpg_lstm/600016/best.pt
```

#### 3. 获取交易建议
```bash
python main.py suggest --code 600016 --balance 100000 --shares 1000 --initial 200000
```

### 参数详解

| 参数 | 说明 | 默认值 | 示例 |
|------|------|--------|------|
| `--code` | 股票代码 | 必填 | 600016 |
| `--reward` | 奖励函数类型(1-5) | 3 | 3 |
| `--seed` | 随机种子 | 1234 | 1234 |
| `--model_type` | 模型类型 | ddpg | ddpg/ddpg_lstm |
| `--seq_len` | LSTM序列长度 | 10 | 10 |
| `--model` | 模型路径 | 自动生成 | ./models/xxx/best.pt |
| `--balance` | 可用余额 | - | 100000 |
| `--shares` | 持股数量 | - | 1000 |
| `--initial` | 初始资金 | - | 200000 |

## 奖励函数设计

系统提供5种奖励函数，适应不同的交易策略和风险偏好：

| 类型 | 特点 | 适用场景 |
|------|------|----------|
| 1 | 直接资产变化奖励 | 追求绝对收益 |
| 2 | 收益率奖励+亏损惩罚 | 风险厌恶型策略 |
| 3 | 复杂交易动作奖励（推荐） | 平衡收益与风险 |
| 4 | 日内价差奖励 | 短线交易策略 |
| 5 | 替代价差奖励 | 特殊市场条件 |

## 性能指标说明

### 收益指标
- **最终收益率**：投资期间总收益率
- **最大收益率**：期间内达到的最高收益率
- **年化收益率**：基于复利计算的年化收益
- **超额收益**：相对买入持有策略的超额表现

### 风险指标
- **最大回撤**：从峰值到谷值的最大损失
- **年化波动率**：收益率的年化标准差
- **夏普比率**：风险调整后收益指标
  - 计算公式：`(年化收益率 - 无风险利率) / 年化波动率`
  - 评价标准：
    - \> 2.0：非常优秀
    - 1.0-2.0：优秀
    - 0.5-1.0：良好
    - 0-0.5：一般
    - < 0：较差

### 交易统计
- **交易频率**：买入/卖出操作次数
- **胜率分析**：盈利交易占比
- **日收益率分布**：收益的统计特征

## 输出文件说明

### 测试结果文件
- **详细记录**：`./results/{股票代码}_test_detail_{时间戳}.csv`
  - 包含每日交易记录、持仓变化、收益率等详细信息
- **汇总报告**：`./results/{股票代码}_test_summary_{时间戳}.txt`
  - 包含性能指标、风险分析、交易统计等汇总信息
- **可视化图表**：`./results/{股票代码}_test_result.png`
  - 策略收益曲线与基准对比图

### 模型文件
- **训练模型**：`./models/reward-{类型}/{股票代码}/best.pt`
  - 训练完成的最优模型文件

## 工作流程

1. **数据准备** → 获取历史股票数据
2. **模型训练** → 选择合适的奖励函数和模型类型进行训练
3. **回测评估** → 使用训练好的模型进行历史数据回测
4. **参数调优** → 根据回测结果调整超参数
5. **实盘应用** → 获取实时交易建议

## 项目局限性与改进方向

### 当前局限性
1. **数据覆盖**：仅针对单只股票的日K线数据，样本有限
2. **交易假设**：采用收盘价/开盘价成交，未考虑大资金影响
3. **市场环境**：未考虑极端市场条件和制度变化

### 改进方向
1. **扩展数据源**：
   - 支持多只股票联合训练
   - 集成高频交易数据
   - 加入宏观经济指标

2. **优化交易模型**：
   - 引入VWAP成交价格模型
   - 考虑交易成本和滑点
   - 增加资金管理约束

3. **增强算法**：
   - 集成Transformer等先进架构
   - 支持多时间框架决策
   - 加入市场状态识别

